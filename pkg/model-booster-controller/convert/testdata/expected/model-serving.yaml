apiVersion: workload.serving.volcano.sh/v1alpha1
kind: ModelServing
metadata:
  labels:
    workload.serving.volcano.sh/backend-name: backend1
    workload.serving.volcano.sh/managed-by: workload.serving.volcano.sh
    workload.serving.volcano.sh/model-name: test-model
    workload.serving.volcano.sh/model-uid: randomUID
    workload.serving.volcano.sh/revision: 69d86dd864
  name: test-model-backend1
  namespace: default
  ownerReferences:
    - apiVersion: workload.serving.volcano.sh/v1alpha1
      kind: ModelBooster
      name: test-model
      uid: randomUID
spec:
  replicas: 0
  schedulerName: ""
  template:
    restartGracePeriodSeconds: 60
    gangPolicy:
      minRoleReplicas:
        leader: 0
    roles:
      - entryTemplate:
          metadata:
            labels:
              workload.serving.volcano.sh/backend-name: backend1
              workload.serving.volcano.sh/managed-by: workload.serving.volcano.sh
              workload.serving.volcano.sh/model-name: test-model
              workload.serving.volcano.sh/model-uid: randomUID
              workload.serving.volcano.sh/revision: 69d86dd864
          spec:
            containers:
              - args:
                  - --port
                  - "8900"
                  - --engine
                  - vllm
                  - --engine-base-url
                  - http://localhost:8000
                  - --engine-metrics-path
                  - /metrics
                  - --pod
                  - $(POD_NAME).$(NAMESPACE)
                  - --model
                  - test-model
                env:
                  - name: ENDPOINT
                    value: https://obs.test.com
                  - name: RUNTIME_PORT
                    value: "8900"
                  - name: POD_NAME
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.name
                  - name: NAMESPACE
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.namespace
                  - name: VLLM_USE_V1
                    value: "1"
                  - name: REDIS_HOST
                    valueFrom:
                      configMapKeyRef:
                        key: REDIS_HOST
                        name: redis-config
                        optional: true
                  - name: REDIS_PORT
                    valueFrom:
                      configMapKeyRef:
                        key: REDIS_PORT
                        name: redis-config
                        optional: true
                  - name: REDIS_PASSWORD
                    valueFrom:
                      secretKeyRef:
                        key: REDIS_PASSWORD
                        name: redis-secret
                        optional: true
                envFrom:
                  - secretRef:
                      name: "test-secret"
                image: kthena/runtime:latest
                name: runtime
                ports:
                  - containerPort: 8900
                readinessProbe:
                  httpGet:
                    path: /health
                    port: 8900
                  initialDelaySeconds: 5
                  periodSeconds: 10
                resources: { }
              - command:
                  - bash
                  - -c
                  - chmod u+x /vllm-workspace/vllm/examples/online_serving/multi-node-serving.sh
                    && /vllm-workspace/vllm/examples/online_serving/multi-node-serving.sh
                    leader --ray_cluster_size=2 --num-gpus=1 && python -m vllm.entrypoints.openai.api_server
                    --model /tmp/test/13a7c4d58031cdc502ca1bb4a592f2b9 --block-size 128
                    --gpu-memory-utilization 0.9 --max-model-len 32768 --served-model-name deepseek-v3
                    --tensor-parallel-size 2 --trust-remote-code --distributed_executor_backend ray
                  
                image: vllm-server:latest
                lifecycle:
                  preStop:
                    exec:
                      command:
                        - /bin/sh
                        - -c
                        - |
                          while true; do
                            RUNNING=$(curl -s http://localhost:8000/metrics | grep 'vllm:num_requests_running' | grep -v '#' | awk '{print $2}')
                            WAITING=$(curl -s http://localhost:8000/metrics | grep 'vllm:num_requests_waiting' | grep -v '#' | awk '{print $2}')
                            if [ "$RUNNING" = "0.0" ] && [ "$WAITING" = "0.0" ]; then
                              echo "Terminating: No active or waiting requests, safe to terminate" >> /proc/1/fd/1
                              exit 0
                            else
                              echo "Terminating: Running: $RUNNING, Waiting: $WAITING" >> /proc/1/fd/1
                              sleep 5
                            fi
                          done
                name: engine
                env:
                  - name: "ENDPOINT"
                    value: "https://obs.test.com"
                  - name: RUNTIME_PORT
                    value: "8900"
                  - name: POD_NAME
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.name
                  - name: NAMESPACE
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.namespace
                  - name: VLLM_USE_V1
                    value: "1"
                  - name: REDIS_HOST
                    valueFrom:
                      configMapKeyRef:
                        key: REDIS_HOST
                        name: redis-config
                        optional: true
                  - name: REDIS_PORT
                    valueFrom:
                      configMapKeyRef:
                        key: REDIS_PORT
                        name: redis-config
                        optional: true
                  - name: REDIS_PASSWORD
                    valueFrom:
                      secretKeyRef:
                        key: REDIS_PASSWORD
                        name: redis-secret
                        optional: true
                readinessProbe:
                  failureThreshold: 3
                  httpGet:
                    path: /health
                    port: 8000
                    scheme: HTTP
                  initialDelaySeconds: 90
                  periodSeconds: 5
                  successThreshold: 1
                  timeoutSeconds: 1
                resources:
                  requests:
                    cpu: 100m
                    huawei.com/ascend-1980: "1"
                    memory: 1Gi
                volumeMounts:
                  - mountPath: /tmp/test
                    name: backend1-weights
            initContainers:
              - args:
                  - --source
                  - s3://aios_models/deepseek-ai/DeepSeek-V3-W8A8/vllm-ascend
                  - --output-dir
                  - /tmp/test/13a7c4d58031cdc502ca1bb4a592f2b9
                image: kthena/downloader:latest
                env:
                  - name: "ENDPOINT"
                    value: "https://obs.test.com"
                envfrom:
                  - secretRef:
                      name: "test-secret"
                name: test-model-model-downloader
                resources: { }
                volumeMounts:
                  - mountPath: /tmp/test
                    name: backend1-weights
              
            terminationGracePeriodSeconds: 300
            volumes:
              - hostPath:
                  path: /tmp/test
                  type: DirectoryOrCreate
                name: backend1-weights
        name: leader
        replicas: 0
        workerReplicas: 1
        workerTemplate:
          spec:
            containers:
              - command:
                  - bash
                  - -c
                  - chmod u+x /vllm-workspace/vllm/examples/online_serving/multi-node-serving.sh
                    && /vllm-workspace/vllm/examples/online_serving/multi-node-serving.sh
                    worker --ray_address=$(ENTRY_ADDRESS)
                env:
                  - name: "ENDPOINT"
                    value: "https://obs.test.com"
                  - name: RUNTIME_PORT
                    value: "8900"
                image: vllm-server:latest
                name: backend1-vllm-worker
                resources:
                  requests:
                    cpu: 100m
                    huawei.com/ascend-1980: "1"
                    memory: 1Gi
                volumeMounts:
                  - mountPath: /tmp/test
                    name: backend1-weights
            initContainers:
              - args:
                  - --source
                  - s3://aios_models/deepseek-ai/DeepSeek-V3-W8A8/vllm-ascend
                  - --output-dir
                  - /tmp/test/13a7c4d58031cdc502ca1bb4a592f2b9
                image: kthena/downloader:latest
                env:
                  - name: "ENDPOINT"
                    value: "https://obs.test.com"
                envfrom:
                  - secretRef:
                      name: "test-secret"
                name: test-model-model-downloader
                resources: { }
                volumeMounts:
                  - mountPath: /tmp/test
                    name: backend1-weights
              
            volumes:
              - hostPath:
                  path: /tmp/test
                  type: DirectoryOrCreate
                name: backend1-weights
  topologySpreadConstraints:
    - labelSelector:
        matchLabels:
          modelserving.volcano.sh/name: test-model
      maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
